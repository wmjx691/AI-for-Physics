{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\nimport os\nfor dirname in os.listdir('/kaggle/input/phys591000-2022-week12-1/'):\n    print(dirname,\"/\")\n#     for filename in os.listdir('/kaggle/input/phys591000-2022-week12-1/'+ dirname):\n#         print(filename)\n#     print(\"\\n\")\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-04T03:45:06.935402Z","iopub.execute_input":"2022-05-04T03:45:06.93572Z","iopub.status.idle":"2022-05-04T03:45:06.962379Z","shell.execute_reply.started":"2022-05-04T03:45:06.935646Z","shell.execute_reply":"2022-05-04T03:45:06.961552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare MNIST. No need for y (labels). Use test + train all together\n\nmnist = np.load('/kaggle/input/mnist-numpy/mnist.npz')\nx_train = mnist['x_train']/255.\nx_test = mnist['x_test']/255.\nmnist_digits = np.concatenate([x_train, x_test], axis=0)\n\nprint('mnist_digits shape is: ', mnist_digits.shape)\n\n#input shape will be (28,28,1)\nmnist_digits = np.expand_dims(mnist_digits, -1)\nprint('mnist_digits shape is now: ', mnist_digits.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:45:06.963794Z","iopub.execute_input":"2022-05-04T03:45:06.964158Z","iopub.status.idle":"2022-05-04T03:45:07.635412Z","shell.execute_reply.started":"2022-05-04T03:45:06.964118Z","shell.execute_reply":"2022-05-04T03:45:07.634517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NOTE: NEED to us tensorflow.keras to import stuff!!\nimport tensorflow as tf\n#from tensorflow.keras.models import Model\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n# Import all layers!\n#from tensorflow.keras.layers import *\n#from tensorflow.keras.optimizers import SGD, Adadelta, Adam, RMSProp\n\n# Create sampling layer\n# Reason for using subclass instead of Lambda layer is saving and inspecting a Model. \n# Models that rely on subclassed Layers are also often easier to visualize and reason about.\n\n# Call: Transform inputs to outputs\n# backend: Keras doesn't handle low-level operations such as tensor products, convolutions, etc.\n\nclass Sampling(layers.Layer):\n    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n\n    def call(self, inputs):\n        z_mean, z_log_var = inputs\n        batch = tf.shape(z_mean)[0]\n        dim = tf.shape(z_mean)[1]\n        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:45:07.63673Z","iopub.execute_input":"2022-05-04T03:45:07.636982Z","iopub.status.idle":"2022-05-04T03:45:12.85024Z","shell.execute_reply.started":"2022-05-04T03:45:07.636948Z","shell.execute_reply":"2022-05-04T03:45:12.849492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoder with latent space dim = 2\n# Build with functional API to specify which layers are connected\n\nlatent_dim = 2\n\nencoder_inputs = keras.Input(shape=(28, 28, 1))\nx = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\nx = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.Flatten()(x)\nx = layers.Dense(16, activation=\"relu\")(x)\nz_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\nz_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\nz = Sampling()([z_mean, z_log_var])\nencoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\nencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:45:12.851996Z","iopub.execute_input":"2022-05-04T03:45:12.852248Z","iopub.status.idle":"2022-05-04T03:45:15.111271Z","shell.execute_reply.started":"2022-05-04T03:45:12.852214Z","shell.execute_reply":"2022-05-04T03:45:15.110596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decoder\nlatent_inputs = keras.Input(shape=(latent_dim,))\nx = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\nx = layers.Reshape((7, 7, 64))(x)\nx = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\ndecoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\ndecoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\ndecoder.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:45:15.112648Z","iopub.execute_input":"2022-05-04T03:45:15.113482Z","iopub.status.idle":"2022-05-04T03:45:15.173664Z","shell.execute_reply.started":"2022-05-04T03:45:15.113442Z","shell.execute_reply":"2022-05-04T03:45:15.172997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the VAE as a Model with a custom train_step\nclass VAE(keras.Model):\n    def __init__(self, encoder, decoder, **kwargs):\n        super(VAE, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n        self.reconstruction_loss_tracker = keras.metrics.Mean(\n            name=\"reconstruction_loss\"\n        )\n        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n\n    @property\n    def metrics(self):\n        return [\n            self.total_loss_tracker,\n            self.reconstruction_loss_tracker,\n            self.kl_loss_tracker,\n        ]\n\n    def train_step(self, data):\n        with tf.GradientTape() as tape:\n            z_mean, z_log_var, z = self.encoder(data)\n            reconstruction = self.decoder(z)\n            reconstruction_loss = tf.reduce_mean(\n                tf.reduce_sum(\n                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n                )\n            )\n            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n            total_loss = reconstruction_loss + kl_loss\n        grads = tape.gradient(total_loss, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n        self.total_loss_tracker.update_state(total_loss)\n        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n        self.kl_loss_tracker.update_state(kl_loss)\n        return {\n            \"loss\": self.total_loss_tracker.result(),\n            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n            \"kl_loss\": self.kl_loss_tracker.result(),\n        }\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T03:45:15.175165Z","iopub.execute_input":"2022-05-04T03:45:15.175428Z","iopub.status.idle":"2022-05-04T03:45:15.1882Z","shell.execute_reply.started":"2022-05-04T03:45:15.175393Z","shell.execute_reply":"2022-05-04T03:45:15.187476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the VAE\nvae = VAE(encoder, decoder)\nvae.compile(optimizer=keras.optimizers.Adam())\nvae.fit(mnist_digits, epochs=30, batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T02:42:03.193521Z","iopub.execute_input":"2022-05-04T02:42:03.193936Z","iopub.status.idle":"2022-05-04T02:44:26.581449Z","shell.execute_reply.started":"2022-05-04T02:42:03.193897Z","shell.execute_reply":"2022-05-04T02:44:26.580609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display a grid of sampled digits\n\n\n# display a n*n 2D manifold of digits\ndigit_size = 28\nscale = 1.0\nn=10\nfigsize=10\n    \nfigure = np.zeros((digit_size * n, digit_size * n))\n# linearly spaced coordinates corresponding to the 2D plot\n# of digit classes in the latent space\ngrid_x = np.linspace(-scale, scale, n)\ngrid_y = np.linspace(-scale, scale, n)[::-1]\n\nfor i, yi in enumerate(grid_y):\n    for j, xi in enumerate(grid_x):\n        z_sample = np.array([[xi, yi]])\n        x_decoded = vae.decoder.predict(z_sample)\n        digit = x_decoded[0].reshape(digit_size, digit_size)\n        figure[\n            i * digit_size : (i + 1) * digit_size,\n            j * digit_size : (j + 1) * digit_size,\n        ] = digit\n\nplt.figure(figsize=(figsize, figsize))\nstart_range = digit_size // 2\nend_range = n * digit_size + start_range\npixel_range = np.arange(start_range, end_range, digit_size)\nsample_range_x = np.round(grid_x, 1)\nsample_range_y = np.round(grid_y, 1)\nplt.xticks(pixel_range, sample_range_x)\nplt.yticks(pixel_range, sample_range_y)\nplt.xlabel(\"z[0]\")\nplt.ylabel(\"z[1]\")\nplt.imshow(figure, cmap=\"Greys_r\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T02:44:26.582699Z","iopub.execute_input":"2022-05-04T02:44:26.583384Z","iopub.status.idle":"2022-05-04T02:44:31.063568Z","shell.execute_reply.started":"2022-05-04T02:44:26.583346Z","shell.execute_reply":"2022-05-04T02:44:31.062917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}