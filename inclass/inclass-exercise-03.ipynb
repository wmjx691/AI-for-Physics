{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Regression Task: Predicting energy of neutrinos \n\nThis week we will use the data from the neutrino experiment, the Oscillation Project with Emulsion-tRacking Apparatus (OPERA). We want to find the relation of the energy of the shower created by a neutrino and the number of hits in the detector.\n\nLet's first load the data and see what are inside. Run the first cell to find the path and names of the datasets.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-02T06:20:30.058799Z","iopub.execute_input":"2022-03-02T06:20:30.059383Z","iopub.status.idle":"2022-03-02T06:20:30.088708Z","shell.execute_reply.started":"2022-03-02T06:20:30.059262Z","shell.execute_reply":"2022-03-02T06:20:30.088049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As usual there are 'training' and 'test' datasets. For the in-class exercise let's focus on the training data.\n\nPlease load the neutrino_train.npz and print out its content in the next cell.","metadata":{}},{"cell_type":"code","source":"neutrino_file = np.load('/kaggle/input/phys591000-2022-week03/neutrino_train.npz')\n\ncontent_names = neutrino_file.files\nprint(content_names)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T06:20:30.090106Z","iopub.execute_input":"2022-03-02T06:20:30.090507Z","iopub.status.idle":"2022-03-02T06:20:30.102081Z","shell.execute_reply.started":"2022-03-02T06:20:30.090474Z","shell.execute_reply":"2022-03-02T06:20:30.101335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see the data contain `Ntotal`, `Nmax`, `izmax` and `Energy`. The meanings are\n\n* `Energy`: Electron neutrino energy\n\n* `Ntotal`: Total number of hits\n\n* `Nmax`: Max hit multiplicity in one layer of the detector\n\n* `izmax`: Max depth of the shower\n\nMake a few plots showing the relations of e.g. Energy v.s. Ntotal, Energy v.s. Nmax. Do the plots make sense?","metadata":{}},{"cell_type":"code","source":"Energy = neutrino_file['Energy']\nNtotal = neutrino_file['Ntotal']\nNmax = neutrino_file['Nmax']\nizmax = neutrino_file['izmax']\n\nprint('Energy shape is:', Energy.shape)\nprint('Ntotal shape is:', Ntotal.shape)\n\nimport matplotlib.pyplot as plt\n# Please make some plots showing the relations of the features below\nfig = plt.figure(figsize=(6,5), dpi=80)\nplt.scatter(Nmax, Energy)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T06:20:30.103959Z","iopub.execute_input":"2022-03-02T06:20:30.104417Z","iopub.status.idle":"2022-03-02T06:20:30.365354Z","shell.execute_reply.started":"2022-03-02T06:20:30.104384Z","shell.execute_reply":"2022-03-02T06:20:30.364356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You should see that Energy is almost linearly proportional to the total number of hits (Ntotal). So we can do a linear regression fit to predict Energy from Ntotal!\n\nIn the cell below we fit Energy (y-axis) v.s. Ntotal (x-axis) with a line, and plot the fitted line against the input data.\n\nNote that input data for sklearn linear regression need to be two-dimensional arrays of shape (n_samples, n_features). This is the case even if you only have one feature. So we use **np.newaxis** to transform Ntotal to a 2D array.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\n\n# Build the linear regression model.  \n# fit_intercept=False means we think Ntotal = 0 corresponds to Energy = 0\n# i.e. no interecept on the y-axis\n\nmodel = LinearRegression(fit_intercept=False)\nx = Ntotal\ny = Energy\nmodel.fit(x[:, np.newaxis], y)\n\n# Fitted line from the linear model\nxfit = np.linspace(0, np.max(Ntotal), 1000)\nyfit = model.predict(xfit[:, np.newaxis])\n\n# compare the fitted line with the data\nplt.scatter(x, y)\nplt.plot(xfit, yfit, 'r')\nplt.ylabel(\"Energy\")\nplt.xlabel(\"Ntotal\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T06:20:30.366784Z","iopub.execute_input":"2022-03-02T06:20:30.367022Z","iopub.status.idle":"2022-03-02T06:20:31.69538Z","shell.execute_reply.started":"2022-03-02T06:20:30.366993Z","shell.execute_reply":"2022-03-02T06:20:31.694296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next we demonstrate how to do a polynomial fit. We need to use **PolynomialFeatures** to 'pre-process' the feature into a polynomail, then use Linear Regression to fit the data with this polynomial. Thus we need to use **Pipeline** to chain these steps together.","metadata":{}},{"cell_type":"code","source":"# Polynomial Regression test\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\n\n# include_bias=False to set the intercept on the y-axis to 0 for polynomial fit\n# For fun try a 5th degree polynomial\nmodel_poly = Pipeline([('poly', PolynomialFeatures(degree=5, include_bias=False)),\n                       ('linear', LinearRegression(fit_intercept=False))])\n\nresult_poly = model_poly.fit(x[:, np.newaxis], y)\n\n# Get the output coefficients in the order of the result 'get_feature_names()'\nmodel_poly.steps[0][1].get_feature_names()\ncoef = result_poly['linear'].coef_\nprint(\"Coefficients from polynomial regression are: \", coef)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T06:20:31.696519Z","iopub.execute_input":"2022-03-02T06:20:31.696745Z","iopub.status.idle":"2022-03-02T06:20:31.712536Z","shell.execute_reply.started":"2022-03-02T06:20:31.696703Z","shell.execute_reply":"2022-03-02T06:20:31.711215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What does the fitted polynomial look like? Please plot the fitted polynomial and compare to the input data in the cell below.","metadata":{}},{"cell_type":"code","source":"# Plot the fit result from the polynomial fit and the input data on the same plot\n\n# Plot using model.predict\nxfit = np.linspace(0, np.max(Ntotal), 100)\nyfit = model_poly.predict(xfit[:, np.newaxis])\n\nplt.scatter(x, y)\nplt.plot(xfit, yfit, 'r')\nplt.ylabel(\"Energy\")\nplt.xlabel(\"Ntotal\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T06:20:31.714597Z","iopub.execute_input":"2022-03-02T06:20:31.715105Z","iopub.status.idle":"2022-03-02T06:20:31.90687Z","shell.execute_reply.started":"2022-03-02T06:20:31.715055Z","shell.execute_reply":"2022-03-02T06:20:31.90579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the next cell we'll demonstrate the effect of overfitting and how to regularize it. As a toy model, we will use only 4 events (samples) from the data, and we will use the feature 'Nmax'. First we'll fit it with a 4th degree polynomial.","metadata":{}},{"cell_type":"code","source":"# Select 4 events from the input\n\nwanted_point = np.arange(0,120, 30)\nx_1= Nmax[wanted_point]\ny_1 = Energy[wanted_point]\n\noverfit = Pipeline([('poly', PolynomialFeatures(degree=4)),\n                       ('linear', LinearRegression())])\n\nresult_overfit = overfit.fit(x_1[:, np.newaxis], y_1)\n\n# Plot using model.predict\nx_1_fit = np.linspace(np.min(x_1), np.max(x_1), 100)\ny_1_fit = overfit.predict(x_1_fit[:, np.newaxis])\n\nplt.scatter(x_1, y_1)\nplt.plot(x_1_fit, y_1_fit,'r')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T06:20:31.908154Z","iopub.execute_input":"2022-03-02T06:20:31.908453Z","iopub.status.idle":"2022-03-02T06:20:32.121714Z","shell.execute_reply.started":"2022-03-02T06:20:31.908409Z","shell.execute_reply":"2022-03-02T06:20:32.120757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see we make a 'perfect' fit of the 4 points. But can this perfect fit generalize to other data points? Let's try out in the next cell.","metadata":{}},{"cell_type":"code","source":"more_points = np.arange(0,120, 10)\nx_2= Nmax[more_points]\ny_2 = Energy[more_points]\n\n# make a plot comparing the fitted result from the previous cell to this set of data\nx_2_fit = np.linspace(np.min(x_2), np.max(x_2), 100)\ny_2_fit = overfit.predict(x_2_fit[:, np.newaxis])\n\nplt.scatter(x_2, y_2)\nplt.plot(x_2_fit, y_2_fit,'r')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T06:20:32.123485Z","iopub.execute_input":"2022-03-02T06:20:32.124014Z","iopub.status.idle":"2022-03-02T06:20:32.263084Z","shell.execute_reply.started":"2022-03-02T06:20:32.123966Z","shell.execute_reply":"2022-03-02T06:20:32.262214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"How about we fit the 4 points with some regularization? In the next cell we will show how to make a polynomial fit with Lasso regularization.","metadata":{}},{"cell_type":"code","source":"# Try regularization\n# alpha is the coefficient of the penalty term\n\nmodel_Lasso = Pipeline([('poly', PolynomialFeatures(degree=4)),\n                ('linear', Lasso(alpha=1))])\n\nresult_Lasso = model_Lasso.fit(x_1[:, np.newaxis], y_1)\n\n# Please compare the fitted result with the 4 points *and* the set from 'more_points'\n\n# Plot using model.predict\nx_3_fit = np.linspace(np.min(x_1), np.max(x_1), 100)\ny_3_fit = result_Lasso.predict(x_3_fit[:, np.newaxis])\n\nplt.scatter(x_1, y_1)\nplt.plot(x_3_fit, y_3_fit,'r')\nplt.show()\n\nx_4_fit = np.linspace(np.min(x_2), np.max(x_2), 100)\ny_4_fit = result_Lasso.predict(x_4_fit[:, np.newaxis])\n\nplt.scatter(x_2, y_2)\nplt.plot(x_4_fit, y_4_fit,'r')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T06:20:32.26485Z","iopub.execute_input":"2022-03-02T06:20:32.265334Z","iopub.status.idle":"2022-03-02T06:20:32.613205Z","shell.execute_reply.started":"2022-03-02T06:20:32.265288Z","shell.execute_reply":"2022-03-02T06:20:32.612503Z"},"trusted":true},"execution_count":null,"outputs":[]}]}